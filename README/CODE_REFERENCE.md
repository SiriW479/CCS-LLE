# CCS-LLE ä»£ç æ˜ å°„é€ŸæŸ¥è¡¨

## ğŸ“Œ æŒ‰åŠŸèƒ½å¿«é€ŸæŸ¥æ‰¾

### ğŸ”µ äº®åº¦å¢å¼º (Illumination Enhancement) - RefIE

```python
# æ–‡ä»¶: ref_exposure_combine_clean.py

ã€å…¨å±€äº®åº¦å°ºåº¦ä¼°è®¡ã€‘
class ScaleYUVBlock(nn.Module):
    def __init__(self, channel=64, kernel_size=3):
        # æ ¸å¿ƒå‚æ•°
        self.conv0 = nn.Conv2d(2, channel, kernel_size*3, padding=4)  # 9Ã—9æ ¸
        self.maxpool = nn.MaxPool2d(kernel_size*3, stride=4, padding=4)
        self.avgpool = nn.AvgPool2d(kernel_size*3, stride=4, padding=4)
        
        # å¤šå±‚çº§èåˆ
        self.conv1 = nn.Conv2d(channel*2, channel, kernel_size*3, padding=4)
        self.conv2 = nn.Conv2d(channel*2, channel, kernel_size*3, padding=4)
        self.conv3 = nn.Conv2d(channel, 3, 1)  # è¾“å‡º3é€šé“å°ºåº¦
    
    def forward(self, x, ref_y):
        # x: [Y_LSR, ref_Y] æ‹¼æ¥ (B, 2, H, W)
        # è¾“å‡º: å…¨å±€å°ºåº¦ (B, 3, H, W) âœ…
        
ã€ç»†èŠ‚å¢å¼ºç½‘ç»œã€‘
class SingleDecomNetSplit(nn.Module):
    def __init__(self, layer_num=5, channel=64, kernel_size=3):
        self.conv0 = nn.Conv2d(3, channel, kernel_size*3, padding=4)
        
        # 5å±‚ç‰¹å¾èåˆ
        feature_conv = []
        for idx in range(layer_num):
            feature_conv.append(nn.Sequential(
                nn.Conv2d(channel, channel, kernel_size, padding=1, groups=2),
                nn.ReLU()
            ))
        self.conv = nn.ModuleList(feature_conv)
        
        self.conv1 = nn.Conv2d(channel, 3, kernel_size, padding=1)
        self.tanh = nn.Tanh()
    
    def forward(self, x):
        # æ®‹å·®å­¦ä¹ 
        residual = x
        out = self.conv0(x)
        for idx in range(self.layer_num):
            out = self.conv[idx](out)
        out = self.conv1(out)
        out = self.tanh(out)
        return out + residual  # æ®‹å·®è¿æ¥

ã€å®Œæ•´ç®¡é“ã€‘
class DecomYUVScaleNetSplit(nn.Module):
    def forward(self, x, ref_y, limit=False):
        # æ­¥éª¤1: å…¨å±€å°ºåº¦
        x_y = x[:, 0, :, :].unsqueeze(1)  # æå–Yé€šé“
        global_scale = self.global_scale(x_y, ref_y)
        
        # æ­¥éª¤2: ä½¿ç”¨å°ºåº¦ç¼©æ”¾
        refine_x = x * global_scale
        if limit:
            refine_x[:, 0, :, :].clamp_(min=0, max=1)
            refine_x[:, 1:, :, :].clamp_(min=-0.5, max=0.5)
        
        # æ­¥éª¤3: ç»†èŠ‚å¢å¼º
        final_output = self.enhancement(refine_x)
        return final_output, global_scale
```

**å…³é”®ç‰¹æ€§**:
- âœ… Patch-wise é‡‘å­—å¡” (9Ã—9 â†’ 3Ã—3 stride 4)
- âœ… MaxPool + AvgPool åŒè·¯ç‰¹å¾
- âœ… 3é€šé“ç‹¬ç«‹å°ºåº¦ (Y/U/V)
- âœ… æ®‹å·®å­¦ä¹ é¿å…è¿‡åº¦å¤„ç†

---

### ğŸŸ  å¤–è§‚è¿ç§» (Appearance Transfer) - RefAT

```python
# æ–‡ä»¶: test_flow_sample_refine_res_clean.py

ã€å…‰æµå¼•å¯¼çš„èåˆç½‘ç»œã€‘
class DecomNet_attention(nn.Module):
    def __init__(self, layer_num=5, channel=64, kernel_size=3):
        self.conv0 = nn.Conv2d(7, channel, kernel_size*3, padding=4)  # 9Ã—9æ ¸
        
        # 5å±‚æ³¨æ„åŠ›ç‰¹å¾
        self.conv_l1 = BasicBlock(channel, channel, activation=nn.ReLU(inplace=True))
        self.conv_l2 = BasicBlock(channel, channel, activation=nn.ReLU(inplace=True))
        self.conv_l3 = BasicBlock(channel, channel, activation=nn.ReLU(inplace=True))
        self.conv_l4 = BasicBlock(channel, channel, activation=nn.ReLU(inplace=True))
        self.conv_l5 = BasicBlock(channel, channel, activation=nn.ReLU(inplace=True))
        
        # è¾“å‡º6é€šé“: 3é€šé“å›¾åƒ + 3é€šé“æ©ç 
        self.conv1 = nn.Conv2d(channel, 6, kernel_size, padding=1)
        self.sig = nn.Sigmoid()
    
    def forward(self, x, warp_x, ref_y, strong_mask=False, output_mask=False):
        # è¾“å…¥
        # x: LSRå½©è‰² (3ch)
        # warp_x: å…‰æµå¯¹é½çš„å‚è€ƒ (3ch)
        # ref_y: å‚è€ƒå•è‰² (1ch)
        x = torch.cat((x, warp_x, ref_y), dim=1)  # 7chæ‹¼æ¥
        
        # ç‰¹å¾æå–
        out = self.conv0(x)
        out = self.conv_l1(out)
        out = self.conv_l2(out)
        out = self.conv_l3(out)
        out = self.conv_l4(out)
        out = self.conv_l5(out)
        
        # è¾“å‡º
        out = self.conv1(out)  # (B, 6, H, W)
        out = self.sig(out)  # Sigmoid å½’ä¸€åŒ–
        
        # åˆ†ç¦»å›¾åƒå’Œæ©ç 
        img2 = out.clone()[:, 0:3, :, :]  # èåˆåå›¾åƒ
        mask = out.clone()[:, 3:, :, :]   # èåˆæ©ç 
        
        # è°ƒæ•´UVåˆ°ä¸­å¿ƒ (YUVä¸­ U,V âˆˆ [-0.5, 0.5])
        img2[:, 1, :, :] -= 0.5
        img2[:, 2, :, :] -= 0.5
        
        # å¯é€‰: å¢å¼ºæ©ç å¯¹æ¯”åº¦
        if strong_mask:
            mask = 1 / (1 + torch.exp(-10 * (mask - 0.5)))
        
        # èåˆ: æ©ç åŠ æƒç»„åˆ
        out_refine = img2 * mask + warp_x * (1 - mask)
        
        if output_mask:
            return out_refine, mask
        else:
            return out_refine

ã€å…‰æµè®¡ç®—ã€‘
# æ–‡ä»¶: PWCNet.py
class PWCDCNet(nn.Module):
    def forward(self, x):  # x: [image1(3ch)|image2(3ch)] = 6ch
        C_channel = x.shape[1] // 2
        im1 = x[:, :C_channel, :, :]
        im2 = x[:, C_channel:, :, :]
        
        # 6å±‚ç‰¹å¾é‡‘å­—å¡”
        c11 = self.conv1b(self.conv1aa(self.conv1a(im1)))  # 1/2
        c21 = self.conv1b(self.conv1aa(self.conv1a(im2)))
        ...
        c16 = self.conv6b(self.conv6a(self.conv6aa(c15)))  # 1/64
        c26 = self.conv6b(self.conv6a(self.conv6aa(c25)))
        
        # ä»ç²—åˆ°ç»†ä¼°è®¡å…‰æµ
        corr6 = self.corr(c16, c26)  # ç›¸å…³æ€§ä½“ç§¯ (B, 81, H/64, W/64)
        
        # 6å±‚è§£ç 
        flow6 = ... # ä¼°è®¡æµ
        up_flow6 = self.deconv6(flow6)
        
        # é€’å½’ç²¾åŒ–åˆ°ç¬¬2å±‚
        warp5 = self.warp(c25, up_flow6 * 0.625)
        corr5 = self.corr(c15, warp5)
        ...
        flow5 = ...
        
        # ... (ç¬¬4,3å±‚)
        
        # æœ€ç»ˆç¬¬2å±‚
        corr2 = self.corr(c12, warp2)
        flow2 = ...
        
        # 7å±‚è†¨èƒ€å·ç§¯ç²¾åŒ–
        x = self.dc_conv4(self.dc_conv3(self.dc_conv2(self.dc_conv1(x))))
        flow2 += self.dc_conv7(self.dc_conv6(self.dc_conv5(x)))
        
        return flow2  # (B, 2, H/4, W/4)

ã€å›¾åƒå˜å½¢ã€‘
def warp(x, flo):
    """æ ¹æ®å…‰æµå˜å½¢å›¾åƒ"""
    B, C, H, W = x.size()
    
    # åˆ›å»ºåæ ‡ç½‘æ ¼
    xx = torch.arange(0, W).view(1,-1).repeat(H,1)  # åˆ—åæ ‡
    yy = torch.arange(0, H).view(-1,1).repeat(1,W)  # è¡Œåæ ‡
    xx = xx.view(1,1,H,W).repeat(B,1,1,1)
    yy = yy.view(1,1,H,W).repeat(B,1,1,1)
    grid = torch.cat((xx,yy), 1).float()
    
    # åŠ ä¸Šå…‰æµ
    vgrid = grid + flo  # (B, 2, H, W)
    
    # æ ‡å‡†åŒ–åˆ° [-1, 1]
    vgrid[:, 0, :, :] = 2.0*vgrid[:, 0, :, :].clone()/max(W-1,1) - 1.0
    vgrid[:, 1, :, :] = 2.0*vgrid[:, 1, :, :].clone()/max(H-1,1) - 1.0
    
    # åŒçº¿æ€§æ’å€¼é‡‡æ ·
    vgrid = vgrid.permute(0,2,3,1)
    output = nn.functional.grid_sample(x, vgrid.clone())
    
    # è®¡ç®—æœ‰æ•ˆæ©ç ï¼ˆå¤„ç†è¾¹ç•Œï¼‰
    mask = torch.ones(x.size()).to(x.device)
    mask = nn.functional.grid_sample(mask, vgrid.clone())
    
    mask[mask < 0.9999] = 0
    mask[mask > 0] = 1
    
    return output * mask, mask

ã€å®Œæ•´æ•°æ®æµã€‘
def test_new_bilateral_simulate(args):
    # åŠ è½½æ¨¡å‹
    from ref_exposure_combine_clean import DecomYUVScaleNetSplit
    from test_flow_sample_refine_res_clean import DecomNet_attention
    
    # RefIE: äº®åº¦å¢å¼º
    color_enhanced, scale = ref_ie_net(color_image, mono_image)
    
    # RefAT: å¤–è§‚è¿ç§»
    # æ­¥éª¤1: å…‰æµè®¡ç®—
    flow = pwc_net(torch.cat([mono_ref_expanded, mono_lsr], dim=1))
    
    # æ­¥éª¤2: å›¾åƒå˜å½¢
    warped_ref, mask = warp(color_ref, flow)
    
    # æ­¥éª¤3: èåˆ
    color_transfer = ref_at_net(color_enhanced, warped_ref, mono_lsr)
    
    # RefSR: è‰²åº¦è¶…åˆ†
    final_output = ref_sr_net(color_transfer, mono_hires)
    
    return final_output
```

**å…³é”®ç‚¹**:
- âœ… 7é€šé“è¾“å…¥: [LSR_RGB(3) + warp_ref(3) + LSR_mono(1)]
- âœ… æ©ç èåˆæƒé‡å­¦ä¹ 
- âœ… PWCNeté‡‘å­—å¡”å…‰æµ (6å±‚)
- âœ… grid_sample å¯å¾®åˆ†é‡‡æ ·

---

### ğŸŸ£ è‰²åº¦è¶…åˆ† (Super-Resolution) - RefSR

```python
# æ–‡ä»¶: ref_SR_deshape_clean.py

ã€æ”¹è¿›HDRNetæ¶æ„ã€‘
class HDRNetwoBN(nn.Module):
    def __init__(self, inc=3, outc=3):
        # ç‰¹å¾æå– (Splatåˆ†æ”¯)
        splat_layers = []
        for i in range(4):
            if i == 0:
                splat_layers.append(
                    conv_block(inc, 8, kernel_size=3, stride=2)
                )
            else:
                splat_layers.append(
                    conv_block(8*(2**(i-1)), 8*(2**i), kernel_size=3, stride=2)
                )
        self.splat_conv = nn.Sequential(*splat_layers)  # è¾“å‡º64ch, 1/16åˆ†è¾¨ç‡
        
        # å…¨å±€ä¸Šä¸‹æ–‡åˆ†æ”¯
        self.global_brach = global_brach(64, 64, BN=False)
        
        # æœ¬åœ°ç‰¹å¾
        local_layers = [
            conv_block(64, 64, activation=self.activation, is_BN=False),
            conv_block(64, 64, use_bias=False, activation=None, is_BN=False),
        ]
        self.local_conv = nn.Sequential(*local_layers)
        
        # åŒè¾¹ç½‘æ ¼ç”Ÿæˆ
        self.linear = nn.Conv2d(64, 96, kernel_size=1)  # å…³é”®ï¼96ç»´
        
        # åº”ç”¨é˜¶æ®µ
        self.guide_func = Guide2()          # ç”Ÿæˆå¼•å¯¼å›¾
        self.slice_func = Slice()           # é‡‡æ ·ç³»æ•°
        self.transform_func = Transform()   # åº”ç”¨å˜æ¢
        self.adjustChromeU = adjustChrome() # Ué€šé“å¾®è°ƒ
        self.adjustChromeV = adjustChrome() # Vé€šé“å¾®è°ƒ
    
    def forward(self, low_res_input, full_res_input):
        bs, _, _, _ = low_res_input.size()
        _, _, hh, hw = full_res_input.size()
        
        # æ­¥éª¤1: ç‰¹å¾æå–
        splat_fea = self.splat_conv(low_res_input)  # (B, 64, H/16, W/16)
        
        # æ­¥éª¤2: æœ¬åœ°ç‰¹å¾
        local_fea = self.local_conv(splat_fea)
        
        # æ­¥éª¤3: å…¨å±€ç‰¹å¾
        global_fea = self.global_brach(splat_fea)   # (B, 64, 1, 1)
        
        # æ­¥éª¤4: èåˆ
        fused = self.activation(
            global_fea.view(-1, 64, 1, 1) + local_fea
        )
        fused = self.linear(fused)  # (B, 96, H/16, W/16)
        
        # æ­¥éª¤5: åŒè¾¹ç½‘æ ¼ç”Ÿæˆ
        f_n, f_c, f_h, f_w = fused.size()
        bilateral_grid = fused.view(-1, 12, 8, f_h, f_w)  # 12Ã—8 = 96
        
        # æ­¥éª¤6: å¼•å¯¼å›¾ç”Ÿæˆ
        guidemap = self.guide_func(full_res_input)  # é«˜åˆ†è¾¨ç‡Y
        
        # æ­¥éª¤7: ç³»æ•°é‡‡æ ·
        coeff = self.slice_func(bilateral_grid, guidemap)  # (B, 12, H, W)
        
        # æ­¥éª¤8: å˜æ¢åº”ç”¨
        bufferYUV = self.transform_func(coeff, full_res_input)
        
        # æ­¥éª¤9: è‰²åº¦å¾®è°ƒ
        fake_res_input = f.interpolate(
            low_res_input, size=(hh, hw), mode='bilinear'
        )
        U = self.adjustChromeU(bufferYUV[:, 1, :, :].unsqueeze(1)) + \
            fake_res_input[:, 1, :, :].unsqueeze(1)
        V = self.adjustChromeV(bufferYUV[:, 2, :, :].unsqueeze(1)) + \
            fake_res_input[:, 2, :, :].unsqueeze(1)
        
        # æ­¥éª¤10: è¾“å‡º
        output = torch.cat([bufferYUV[:, 0, :, :].unsqueeze(1), U, V], dim=1)
        return output

ã€å…¨å±€åˆ†æ”¯ã€‘
class global_brach(nn.Module):
    def __init__(self, inc=64, outc=64, BN=True):
        self.average_0 = nn.AdaptiveAvgPool2d((1,1))
        self.conv_1 = conv_block(inc, 2*inc, kernel_size=3, padding=1, stride=2)
        self.average_1 = nn.AdaptiveAvgPool2d((1,1))
        self.conv_2 = conv_block(2*inc, 4*inc, kernel_size=3, padding=1, stride=2)
        self.average_2 = nn.AdaptiveAvgPool2d((1,1))
        
        # èåˆ
        self.fuse_1 = conv_block(7*inc, 4*inc, kernel_size=1, padding=0)
        self.fuse_2 = conv_block(4*inc, 2*inc, kernel_size=1, padding=0)
        self.fuse_3 = conv_block(2*inc, 1*inc, kernel_size=1, padding=0)
    
    def forward(self, x):
        # å¤šå±‚çº§ç‰¹å¾æå–
        a0 = self.average_0(x)  # (B, 64, 1, 1)
        
        x = self.conv_1(x)
        a1 = self.average_1(x)  # (B, 128, 1, 1)
        
        x = self.conv_2(x)
        a2 = self.average_2(x)  # (B, 256, 1, 1)
        
        # æ‹¼æ¥: (B, 448, 1, 1) = 64+128+256
        a = torch.cat((a0, a1, a2), dim=1)
        
        # çº§è”èåˆ
        a = self.fuse_1(a)  # 448 â†’ 256
        a = self.fuse_2(a)  # 256 â†’ 128
        a = self.fuse_3(a)  # 128 â†’ 64
        
        return a  # (B, 64, 1, 1)

ã€å¼•å¯¼å›¾ç”Ÿæˆã€‘
class Guide2(nn.Module):
    def __init__(self, mode="PointwiseNN"):
        self.mode = "PointwiseNN"
        self.conv1 = conv_block(1, 16, kernel_size=3, stride=1, is_BN=False)
        self.conv2 = conv_block(16, 1, kernel_size=1, padding=0, 
                               activation=nn.Tanh())
    
    def forward(self, x):
        # è¾“å…¥: é«˜åˆ†è¾¨ç‡Yé€šé“
        guidemap = self.conv2(self.conv1(x))
        return guidemap

ã€ç³»æ•°é‡‡æ ·ã€‘
class Slice(nn.Module):
    def forward(self, bilateral_grid, guidemap):
        # bilateral_grid: (B, 12, 8, H/16, W/16)
        # guidemap: (B, 1, H, W) é«˜åˆ†è¾¨ç‡
        
        N, _, H, W = guidemap.shape
        
        # åˆ›å»ºå½’ä¸€åŒ–åæ ‡ç½‘æ ¼
        xx = torch.arange(0, W).view(1,-1).repeat(H,1)
        yy = torch.arange(0, H).view(-1,1).repeat(1,W)
        xx = xx.view(1,1,H,W).repeat(N,1,1,1)
        yy = yy.view(1,1,H,W).repeat(N,1,1,1)
        xx = 2.0*xx/max(W-1,1) - 1.0
        yy = 2.0*yy/max(H-1,1) - 1.0
        grid = torch.cat((xx,yy), 1).float()
        
        # æ‹¼æ¥åæ ‡å’Œå¼•å¯¼å›¾
        guidemap_guide = torch.cat([grid, guidemap], dim=1)  # (B, 3, H, W)
        guidemap_guide = guidemap_guide.permute(0,2,3,1).contiguous()
        guidemap_guide = guidemap_guide.unsqueeze(1)  # (B, 1, H, W, 3)
        
        # é‡‡æ ·
        coeff = f.grid_sample(bilateral_grid, guidemap_guide)
        
        return coeff.squeeze(2)  # (B, 12, H, W)

ã€å˜æ¢åº”ç”¨ã€‘
class Transform(nn.Module):
    def forward(self, coeff, full_res_input):
        # coeff: (B, 12, H, W)
        # full_res_input: (B, 1, H, W) é«˜åˆ†è¾¨ç‡Y
        
        Y = full_res_input * coeff[:, 3:4, :, :] + \
            torch.sum(coeff[:, 0:3, :, :], dim=1, keepdim=True)
        
        U = full_res_input * coeff[:, 7:8, :, :] + \
            torch.sum(coeff[:, 4:7, :, :], dim=1, keepdim=True)
        
        V = full_res_input * coeff[:, 11:12, :, :] + \
            torch.sum(coeff[:, 8:11, :, :], dim=1, keepdim=True)
        
        return torch.cat([Y, U, V], dim=1)

ã€è‰²åº¦å¾®è°ƒã€‘
class adjustChrome(nn.Module):
    def __init__(self):
        self.conv1 = conv_block(1, 16, kernel_size=1, padding=0, is_BN=False)
        self.conv2 = conv_block(16, 1, kernel_size=1, padding=0, 
                               activation=nn.Tanh())
    
    def forward(self, chromeInfo):
        chromemap = self.conv1(chromeInfo)
        chromemap = self.conv2(chromemap)  # å¾®è°ƒå€¼
        return chromemap
```

**å…³é”®äº®ç‚¹**:
- âœ… 96ç»´åŒè¾¹ç½‘æ ¼ (12Ã—8)
- âœ… å…¨å±€åˆ†æ”¯å¤šå±‚çº§èšåˆ
- âœ… Guide2 é€åƒç´ å¼•å¯¼
- âœ… å˜æ¢åº”ç”¨åˆ°Y/U/Våˆ†åˆ«
- âœ… è‰²åº¦ç‹¬ç«‹å¾®è°ƒç½‘ç»œ

---

## ğŸ¯ æŸå¤±å‡½æ•°é€ŸæŸ¥

```python
# æ–‡ä»¶: myLoss.py

ã€åˆ†é˜¶æ®µYUVæŸå¤±ã€‘
class YUV_Loss(nn.Module):
    def forward(self, predict, label):
        loss_y = self.loss(predict[:, 0:1], label[:, 0:1])
        loss_u = self.loss(predict[:, 1:2], label[:, 1:2])
        loss_v = self.loss(predict[:, 2:3], label[:, 2:3])
        
        if loss_y.item() > self.threshold_uv:
            # å‰æœŸ: ä¸»è¦å…³æ³¨Y
            total_loss = loss_y + 0.2*loss_u + 0.2*loss_v
        else:
            # åæœŸ: å‡è¡¡å…³æ³¨
            total_loss = loss_y + loss_u + loss_v
        
        return torch.mean(total_loss)

ã€å¹³æ»‘çº¦æŸã€‘
class Image_smooth_loss(nn.Module):
    def forward(self, predicted, label):
        # åŠ æƒTV: w = exp(-Î»|âˆ‡label|)
        predicted_grad_x, predicted_grad_y = self.gradients(predicted)
        label_grad_x, label_grad_y = self.gradients(label)
        
        w_x = torch.exp(-self.TV_scale * torch.abs(label_grad_x))
        w_y = torch.exp(-self.TV_scale * torch.abs(label_grad_y))
        
        error = ((w_x*torch.abs(predicted_grad_x)).mean() +
                 (w_y*torch.abs(predicted_grad_y)).mean())
        return error

ã€å‚è€ƒæ›å…‰ä¸€è‡´æ€§ã€‘
class L_ref_exp(nn.Module):
    def forward(self, x_y, ref_y):
        # Patch-wiseå¹³å‡å€¼åŒ¹é…
        x_mean = self.pool(x_y)      # 16Ã—16 pool
        ref_mean = self.pool(ref_y)
        
        d = torch.mean(torch.abs(torch.pow(x_mean - ref_mean, self.lossN)))
        return d
```

---

## ğŸ“Š æ•°æ®åŠ è½½é€ŸæŸ¥

```python
# æ–‡ä»¶: loadDataset.py

ã€æ ‡å‡†è®­ç»ƒé›†ã€‘
class myBilateralDataset(Dataset):
    def __getitem__(self, idx):
        # åŠ è½½è·¯å¾„
        color = Image.open(self.left_pic_list[idx])      # LSRå½©è‰²
        mono = Image.open(self.right_pic_list[idx])      # LSRå•è‰²
        label = Image.open(self.left_label_pic_list[idx]) # HSRå•è‰²çœŸå€¼
        label_color = Image.open(self.right_label_pic_list[idx]) # HSRå½©è‰²çœŸå€¼
        
        # è½¬numpyå¹¶å½’ä¸€åŒ–åˆ°[0,1]
        color_image = np.array(color).transpose(2,0,1) / 255.0
        mono_source = np.array(mono).transpose(2,0,1) / 255.0
        
        # è½¬Tensor
        colorTensor = torch.from_numpy(color_image)
        monoTensor_ = torch.from_numpy(mono_source)
        
        # å•è‰²è½¬ç°åº¦ (åŠ æƒå¹³å‡)
        h, w = monoTensor_.shape[-2:]
        monoTensor = torch.zeros(1, h, w)
        monoTensor[0,:,:] = (monoTensor_[2,:,:] * 0.114 + 
                             monoTensor_[1,:,:] * 0.587 + 
                             monoTensor_[0,:,:] * 0.299)  # RGBæƒé‡
        
        return {
            'mono': monoTensor,
            'color': colorTensor,
            'label': mono_labelTensor,
            'label_color': color_labelTensor
        }

ã€å¢å¼ºè®­ç»ƒé›†ã€‘
class myEnhanceBilateralDataset(Dataset):
    def __getitem__(self, idx):
        # éšæœºæ›å…‰è°ƒæ•´
        color_adjust = np.random.uniform(0.5, 1.5)
        color_image *= color_adjust
        
        mono_adjust = np.random.uniform(0.9, 1.2)
        mono_source *= mono_adjust
        
        # ... (åŒä¸Š)
```

---

## ğŸ”§ é…ç½®å¸¸æ•°

```python
# RefIE å‚æ•°
ScaleYUVBlock:
    conv0_kernel = 9        # å¤§æ„Ÿå—é‡
    pool_kernel = 9
    pool_stride = 4         # ä¸‹é‡‡æ ·å› å­
    channel = 64            # éšè—é€šé“

# RefAT å‚æ•°
DecomNet_attention:
    conv0_kernel = 9
    layer_num = 5           # 5å±‚BasicBlock
    channel = 64
    output_channel = 6      # 3å›¾åƒ + 3æ©ç 

# RefSR å‚æ•°
HDRNetwoBN:
    splat_layers = 4        # 1/16æœ€ç»ˆåˆ†è¾¨ç‡
    bilateral_grid = 12Ã—8   # 96ç»´
    global_branch = enabled # å…³é”®æ”¹è¿›

# PWCNet å‚æ•°
PWCDCNet:
    md = 4                  # æœ€å¤§ä½ç§»(åƒç´ )
    pyramid_levels = 6      # 6å±‚é‡‘å­—å¡”
    corr_dim = 81           # (2*4+1)Â²
```

---

## âœ… æ¨ç†æ­¥éª¤æ£€æŸ¥æ¸…å•

```
[ ] 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
      â”œâ”€ RefIE: DecomYUVScaleNetSplit()
      â”œâ”€ RefAT: DecomNet_attention()
      â”œâ”€ RefSR: HDRNetwoBN()
      â””â”€ Flow: PWCDCNet() æˆ– PWCDCNetCPU()

[ ] 2. é¢„å¤„ç†è¾“å…¥
      â”œâ”€ LSRå½©è‰²: (B, 3, H, W) å½’ä¸€åŒ–[0,1]
      â”œâ”€ LSRå•è‰²: (B, 1, H, W) æˆ– è½¬ç°åº¦
      â””â”€ RGB â†’ YUV è½¬æ¢

[ ] 3. RefIE äº®åº¦å¢å¼º
      â””â”€ enhanced, scale = ref_ie(color_yuv, mono_yuv)

[ ] 4. RefAT å¤–è§‚è¿ç§»
      â”œâ”€ è®¡ç®—å…‰æµ: flow = pwc_net([mono_up, mono])
      â”œâ”€ å˜å½¢å‚è€ƒ: warp_ref = warp(ref_color, flow)
      â””â”€ èåˆ: transfer = ref_at(enhanced, warp_ref, mono)

[ ] 5. RefSR è‰²åº¦è¶…åˆ†
      â””â”€ final = ref_sr(transfer, hires_mono)

[ ] 6. åå¤„ç†è¾“å‡º
      â””â”€ YUV â†’ RGB è½¬æ¢
      â””â”€ è£å‰ªåˆ° [0,1]
```
